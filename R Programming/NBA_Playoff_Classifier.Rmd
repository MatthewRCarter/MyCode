---
title: "NBA_Playoff_Classifier"
author: "Matt Carter"
date: "May 20, 2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#installing packages
suppressWarnings(library(MASS))
suppressWarnings(library(readxl))
suppressMessages(suppressWarnings(library(tidyverse)))
suppressWarnings(library(dplyr))
suppressWarnings(library(stringr))
#loading data
singe_player_data <-suppressMessages(suppressWarnings(read_xlsx("C:/Users/Matthew/Documents/School/STAT_434/Final_Project/single_player_data_2.xlsx")))
```

# Data Cleaning & Prep

#Filtering out data prior to 2000 because we have other data sources that only go till 1990. Also, the game has changed so much in the last 30 years that I believe that data before this time wouldn't prove useful in prediction settings.
```{r}
post_1990 <- singe_player_data %>%
  filter(Year >= 2000, Tm != "TOT")
```

#Converting season stats to a per game basis
```{r}
games <- 82
team_data <- post_1990 %>%
  group_by(Year, Tm) %>%
  summarise(
    PPG = sum(PTS)/games,
    Assists = sum(AST)/games,
    T_Rebounds = sum(TRB)/games,
    O_Rebounds = sum(ORB)/games,
    D_Rebounds = sum(DRB)/games,
    Steals = sum(STL)/games,
    Blocks = sum(BLK)/games,
    Turnovers = sum(TOV)/games,
    Team_Fouls = sum(PF)/games,
    FGM = sum(FG)/games,
    FGA = sum(FGA)/games,
    FG_Pct = (sum(FG) / sum(FGA)),
    ThreeP_M = sum(ThreeP)/games,
    ThreeP_A = sum(ThreePA)/games,
    Three_Pct = (sum(ThreeP) / sum(ThreePA)),
    TwoP_M = sum(TwoP)/games,
    TwoP_A = sum(TwoPA)/games,
    Two_Pct = (sum(TwoP) / sum(TwoPA)),
    Mean_Age  = mean(Age)
  )
```

#Again, filtering out data before 2000 to ensure successful merging of different data sources.
```{r}
#Loading in Playoff Data
playoff_team_data <-read_xlsx("C:/Users/Matthew/Documents/School/STAT_434/Final_Project/Team_Playoff_Data.xlsx")

playoff_data <- playoff_team_data %>%
  filter(Year >= 2000, Year < 2018)
```

#After thorough research and my own knowledge of the NBA, teams that have shown to perform well in "Clutch" situations are often times those who handle the playoff pressure more effectively. To investigate if this was true, I tracked down clutch statistics for each team. 
```{r}
clutch <- suppressMessages(read_xlsx("C:/Users/Matthew/Documents/School/STAT_434/Final_Project/clutch.xlsx"))
clutch <- clutch[,1:3]
# names(clutch) <- c()
```


#Unfortunately, the team name, which is going to be the 'Primary Key' on which we will merge, was in a different format then in my other data sources. Below you can see function that creates another variable called "Tm" which represents the 3 letter abbreviation of the team
```{r}
team_name_df <- unique(playoff_data["Team"])


team_name_df <- team_name_df %>%
    mutate(Tm = case_when(Team == "Atlanta Hawks" ~ "ATL",
                          Team == "Boston Celtics" ~ "BOS",
                          Team == "Brooklyn Nets" ~ "BRK",
                          Team == "Charlotte Bobcats" ~ "CHA",
                          Team == "Charlotte Hornets" ~ "CHH",
                          Team == "Chicago Bulls" ~ "CHI",
                          Team == "Cleveland Cavaliers" ~ "CLE",
                          Team == "Dallas Mavericks" ~ "DAL",
                          Team == "Denver Nuggets" ~ "DEN",
                          Team == "Detroit Pistons" ~ "DET",
                          Team == "Golden State Warriors" ~ "GSW",
                          Team == "Houston Rockets" ~ "HOU",
                          Team == "Indiana Pacers" ~ "IND",
                          Team == "LA Clippers" ~ "LAC",
                          Team == "Los Angeles Clippers" ~ "LAC",
                          Team == "Los Angeles Lakers" ~ "LAL",
                          Team == "Memphis Grizzlies" ~ "MEM",
                          Team == "Miami Heat" ~ "MIA",
                          Team == "Milwaukee Bucks" ~ "MIL",
                          Team == "Minnesota Timberwolves" ~ "MIN",
                          Team == "New Jersey Nets" ~ "NJN",
                          Team == "New Orleans Hornets" ~ "NOH",
                          Team == "New Orleans/Oklahoma City Hornets" ~ "NOK",
                          Team == "New Orleans Pelicans" ~ "NOP",
                          Team == "New York Knicks" ~ "NYK",
                          Team == "Oklahoma City Thunder" ~ "OKC",
                          Team == "Orlando Magic" ~ "ORL",
                          Team == "Philadelphia 76ers" ~ "PHI",
                          Team == "Phoenix Suns" ~ "PHO",
                          Team == "Portland Trail Blazers" ~ "POR",
                          Team == "Sacramento Kings" ~ "SAC",
                          Team == "San Antonio Spurs" ~ "SAS",
                          Team == "Seattle SuperSonics" ~ "SEA",
                          Team == "Toronto Raptors" ~ "TOR",
                          Team == "Utah Jazz" ~ "UTA",
                          Team == "Vancouver Grizzlies" ~ "VAN",
                          Team == "Washington Wizards" ~ "WAS"
  ))

clutch <- merge(clutch, team_name_df, by = "Team")
playoff_data <- merge(playoff_data, team_name_df, by = "Team")
```

# Final dataset merging
```{r}
library(tidyverse)

#merging data sources to create final dataset
final_dataset <- merge(team_data, playoff_data, by = c("Tm", "Year"))
final_dataset <- merge(final_dataset, clutch, by = c("Tm", "Year"))

final_dataset_1 <- final_dataset %>%
  dplyr::select(Tm, Win, Loss, Playoffs, Win_Loss_Pct, Year:Rel_DRtg, Clutch_Win_Perc, -Lg)
```

### More Data Cleaning 
```{r}

final_dataset_2 <- final_dataset_1 %>%
  mutate(Playoffs_1 = case_when(Playoffs == "Lost E. Conf. 1st Rnd." ~ "1st Round",
                                Playoffs == "Lost W. Conf. 1st Rnd." ~ "1st Round",
                                Playoffs == "Lost E. Conf. Semis" ~ "2nd Round",
                                Playoffs == "Lost W. Conf. Semis" ~ "2nd Round",
                                Playoffs == "Lost E. Conf. Finals" ~ "Conference Finals",
                                Playoffs == "Lost E. Conf. Finals" ~ "Conference Finals",
                                Playoffs == "Won Finals" ~ "Won Finals",
                                Playoffs == "Lost Finals" ~ "Lost Finals",
                                TRUE ~ "No Playoffs"
                                ),
         Playoffs_Quant = case_when(Playoffs == "Lost E. Conf. 1st Rnd." ~ 1,
                                Playoffs == "Lost W. Conf. 1st Rnd." ~ 1,
                                Playoffs == "Lost E. Conf. Semis" ~ 2,
                                Playoffs == "Lost W. Conf. Semis" ~ 2,
                                Playoffs == "Lost E. Conf. Finals" ~ 3,
                                Playoffs == "Lost E. Conf. Finals" ~ 3,
                                Playoffs == "Won Finals" ~ 5,
                                Playoffs == "Lost Finals" ~ 4,
                                TRUE ~ 0
                                )
        )

model_dataset <- final_dataset_2 %>%
  filter(Playoffs_Quant != 0) %>%
  dplyr::select(-Finish)

quant_only <- model_dataset %>%
  dplyr::select(-Tm, -Year, -Season, -Team.x, -Playoffs, -Playoffs_Quant, -ThreeP_A, -Team_Fouls, -D_Rebounds, -Pace, - ThreeP_M, -Blocks) 

quant_only1 <- model_dataset %>%
  dplyr::select(-Tm, -Year, -Season, -Team.x, -Playoffs, -Playoffs_1) 

reduced_dataset <- model_dataset %>%
  dplyr::select(Win,FG_Pct,SRS,Rel_ORtg,Rel_DRtg,Clutch_Win_Perc, Mean_Age, Playoffs_1)

```


# Data Exploration & Variable Selection

#Creating correlation matrix before modeling
```{r}
corr_matrix <- as.data.frame(round(cor(quant_only1),2))
correlate <- as.data.frame(corr_matrix[,30:31]) 
correlate$Variable <- rownames(correlate)
correlate <- correlate[correlate$Variable!="Playoffs_Quant",c("Variable","Playoffs_Quant")]
correlate %>%
  arrange(desc(abs(Playoffs_Quant)))
```

Lost E. Conf. 1st Rnd.
Lost W. Conf. 1st Rnd.
  [1st Round]

Lost E. Conf. Semis
Lost W. Conf. Semis
  [2nd Round]

Lost E. Conf. Finals
Lost W. Conf. Finals
  [Conference Finals]
  
  [Lost Finals]
  [Won Finals]
  [No Playoffs]


#Variable selection using stepwise/best subsets
```{r}
suppressWarnings(suppressMessages(library(leaps)))

mixed_stepwise <- regsubsets(Playoffs_Quant~., data = quant_only1, nvmax = 5, really.big = T)
summary(mixed_stepwise)

str(quant_only1)
```

### Creating Test/Train Sets
#Making train/test sets with 3 different ratios (80/20, 65/35, & 50/50)
```{r}
set.seed(32)
train_1 <- sample(c(TRUE ,FALSE),size = nrow(model_dataset),prob=c(.8,.2),rep=TRUE)
test_1 = (!train_1)

train_2 <- sample(c(TRUE ,FALSE),size = nrow(model_dataset),prob=c(.65,.35),rep=TRUE)
test_2 = (!train_1)

train_3 <- sample(c(TRUE ,FALSE),size = nrow(model_dataset),prob=c(.5,.5),rep=TRUE)
test_3 <- (!train_1)
```

# Quadratic Discriminant Analysis (QDA)

## QDA - Reduced Model
### With the reduced QDA model, I successfully predicted 70% of playoff series from the years of 2000-2018
```{r}
# Fitting Quantitative Discriminant Analysis 
#Reduced Model Function
QDAfunctred <- function(train, test){

  qda.fit <- qda(Playoffs_1 ~ Win + FG_Pct + SRS + Rel_ORtg + Rel_DRtg + Clutch_Win_Perc,data=model_dataset ,subset = train)
  
  qda.pred <- predict(qda.fit,model_dataset[test,])
  
  actual_playoff <- model_dataset$Playoffs_1[test]
  predicted_playoff <- qda.pred$class
  
  #confusion matrix
  qdatable <- table(actual_playoff,predicted_playoff)
  
  classes <- c("1st Round", "2nd Round", "Conference Finals", "Lost Finals", "Won Finals")
  
  correct_perc <- list()
  for (i in 1:length(classes)){
    correct_perc[i] <- mean(predicted_playoff[actual_playoff == classes[i]] == actual_playoff[actual_playoff == classes[i]])
    }
  
  overall_perc <- mean(predicted_playoff == actual_playoff)
  return (list(qdatable, correct_perc,overall_perc)) # Returns a list of list, be wary when calling things
}
```

```{r}
#QDA
library(MASS)
#QDAfunctred(train_1,test_1)
QDAfunctred(train_2,test_2) # Based on the seed used, Correct Prediction changed by 20%
#QDAfunctred(train_3,test_3)
```


# KNN
### With the KNN Model, I successfully predicted 82.5% of playoff series from the years of 2000-2018
```{r}
set.seed(47)
library(class) 
KNNfunc <- function(dataset,train,test){
standardized.X=scale(dataset[,!colnames(dataset) == "Playoffs_1"]) #large matrix of X-values 

#now they are standardized 

#Creating test set and stuff
train.X=standardized.X[-test,]
test.X=standardized.X[test,]
train.Y=quant_only$Playoffs_1[-test]
test.Y=quant_only$Playoffs_1[test]

test.errors <- rep(2, 15) 


for (i in 2:15) {    
		knn.pred <- knn(train.X,test.X,train.Y, k = i)    
    test.errors[i] <- mean(knn.pred != test.Y) 
    } 
test.errors

knn.pred <- knn(train.X,test.X,train.Y, k = (which.min(test.errors) + 1)) 

classes <- c("1st Round", "2nd Round", "Conference Finals", "Lost Finals", "Won Finals")

correct_perc <- list()
for (i in 1:length(classes)){
correct_perc[i] <- mean(knn.pred[test.Y == classes[i]] == test.Y[test.Y == classes[i]])
}

KNNtable <- table(test.Y,knn.pred)
correct_prediction <- mean(knn.pred == test.Y)
return (list(KNNtable,correct_prediction,correct_perc))
}

#Reduced Model
# KNNfunc(reduced_dataset,train_1,test_1)
# KNNfunc(reduced_dataset,train_2,test_2)
# KNNfunc(reduced_dataset,train_3,test_3)

#Full Model
# KNNfunc(quant_only,train_1,test_1)
# KNNfunc(quant_only,train_2,test_2)
KNNfunc(quant_only,train_3,test_3)
```

# Random Forest
### With the Random Forest, I successfully predicted 85% of playoff series from the years of 2000-2018
```{r}
# install.packages("randomForest")
suppressWarnings(suppressMessages(library(randomForest)))
set.seed(1)

forestfunc <- function(train,test) {

  reduced_dataset$Playoffs_1 <- as.factor(reduced_dataset$Playoffs_1)
  str(reduced_dataset$Playoffs_1)
  
  val.errors <- list()
  for (i in 1:6){
    playoff_forest <- randomForest(Playoffs_1~.,data= reduced_dataset[train,], mtry = i, importance = TRUE, type = "classification")
    
    # val.errors[i] <- mean(yhat.bag == quant_only[test,]$Playoffs_1)
    # which.max(val.errors)
    ?randomForest
    
    # get the test MSE
    yhat.bag <- predict(playoff_forest , newdata = reduced_dataset[test,])
    
    val.errors[i] <- mean(yhat.bag == reduced_dataset[test,]$Playoffs_1)
    which.max(val.errors)
    
    val.errors[i] <- mean(yhat.bag == reduced_dataset[test,]$Playoffs_1)
    which.max(val.errors)
  
  }
  
  
  playoff_forest1 <- randomForest(Playoffs_1~.,data= reduced_dataset[train,], mtry = which.max(val.errors), importance =TRUE, type = "classification")
  
  yhat.bag <- predict(playoff_forest1 , newdata = reduced_dataset[test,])
  actual <- reduced_dataset[test,]$Playoffs_1
  foresttable <- table(yhat.bag,actual)
  classes <- c("1st Round", "2nd Round", "Conference Finals", "Lost Finals", "Won Finals")
  correct_perc <- list()
  
  for (i in 1:length(classes)){
    correct_perc[i] <- mean(yhat.bag[actual == classes[i]] == actual[actual == classes[i]])
    }
    perc <- mean(yhat.bag == reduced_dataset[test,]$Playoffs_1)
    var <- varImpPlot (playoff_forest1)
    return (list(foresttable,perc,correct_perc))

}

#forestfunc(train_1,test_1)
forestfunc(train_2,test_2)
#forestfunc(train_3,test_3)
```

```{r}
setwd("C:/Users/Matthew/Documents/School/GSB 510/Final_Presentation")
write_excel_csv2(final_dataset_2, path = "final_dataset_2.xlsx")
```

